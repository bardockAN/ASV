{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9920101,"sourceType":"datasetVersion","datasetId":6096635},{"sourceId":11565412,"sourceType":"datasetVersion","datasetId":7251391},{"sourceId":11776227,"sourceType":"datasetVersion","datasetId":7393408},{"sourceId":11821032,"sourceType":"datasetVersion","datasetId":7425275},{"sourceId":11843572,"sourceType":"datasetVersion","datasetId":7441285}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1 ‚Äì C√†i th∆∞ vi·ªán (ch·∫°y ~2-3 ph√∫t)\n!pip install -q --no-cache-dir torch==2.5.1 torchaudio==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu124\n!pip install -q --no-cache-dir speechbrain==1.0.3\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:43:28.600102Z","iopub.execute_input":"2025-05-30T09:43:28.600936Z","iopub.status.idle":"2025-05-30T09:43:34.999218Z","shell.execute_reply.started":"2025-05-30T09:43:28.600910Z","shell.execute_reply":"2025-05-30T09:43:34.998276Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"# Cell 2 ‚Äì Khai b√°o ƒë∆∞·ªùng d·∫´n & import (cho private-test)\nfrom pathlib import Path\nimport torch, torchaudio, torch.nn.functional as F\nimport tqdm, functools, zipfile, os\n\n# 1) ƒê∆∞·ªùng d·∫´n ƒë·∫øn checkpoints\nCKPT_ROOT    = Path(\"/kaggle/input/checkpointresult/checkpoints\")\n\n# 2) Th∆∞ m·ª•c g·ªëc private-test\nPRIVATE_ROOT = Path(\"/kaggle/input/private-test\")\n\n# 3) L·∫•y folder timestamp con (ch·ª©a audio)\nsubfolders = [p for p in PRIVATE_ROOT.iterdir() if p.is_dir()]\nassert subfolders, f\"Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c con trong {PRIVATE_ROOT}\"\nsub = subfolders[0]\n\n# 4) Folder ch·ª©a .wav\nWAV_DIR   = sub / \"private-test-data-sv\"\n\n# 5) File CSV n·∫±m ngay trong PRIVATE_ROOT (kh√¥ng ph·∫£i trong `sub`)\nPAIR_FILE = PRIVATE_ROOT / \"prompts_sv.csv\"\n\n# 6) ƒê∆∞·ªùng d·∫´n ƒë·∫ßu ra\nOUT_TXT   = Path(\"/kaggle/working/predictions.txt\")\nZIP_PATH  = Path(\"/kaggle/working/submission.zip\")\n\n# 7) Ki·ªÉm tra t·ªìn t·∫°i\nprint(\"‚úÖ WAV_DIR exists?   \", WAV_DIR.exists(),   \"‚Üí\", WAV_DIR)\nprint(\"‚úÖ PAIR_FILE exists?\", PAIR_FILE.exists(),  \"‚Üí\", PAIR_FILE)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:43:35.000880Z","iopub.execute_input":"2025-05-30T09:43:35.001141Z","iopub.status.idle":"2025-05-30T09:43:35.010949Z","shell.execute_reply.started":"2025-05-30T09:43:35.001118Z","shell.execute_reply":"2025-05-30T09:43:35.010363Z"}},"outputs":[{"name":"stdout","text":"‚úÖ WAV_DIR exists?    True ‚Üí /kaggle/input/private-test/private-test-data-sv-20250512T023803Z-001/private-test-data-sv\n‚úÖ PAIR_FILE exists? True ‚Üí /kaggle/input/private-test/prompts_sv.csv\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"# --- CELL 3 -------------------------------------------------------\nfrom speechbrain.inference.speaker import EncoderClassifier\nfrom pathlib import Path\nimport torch, yaml, re, pprint\n\n# 1) N·∫°p ECAPA g·ªëc (SpeechBrain)\npretrained = EncoderClassifier.from_hparams(\n    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n    savedir=\"pretrained_ecapa\",\n    run_opts={\"device\": \"cuda\"}\n)\ncompute_features = pretrained.mods.compute_features\nmean_var_norm   = pretrained.mods.mean_var_norm\nembedding_model = pretrained.mods.embedding_model\nclassifier      = pretrained.mods.classifier\n\n# 2) T√¨m th∆∞ m·ª•c checkpoint m·ªõi nh·∫•t\nckpt_dirs = sorted([d for d in CKPT_ROOT.iterdir() if d.is_dir()],\n                   key=lambda p: p.name)\nassert ckpt_dirs, \"‚ùå  Kh√¥ng t√¨m th·∫•y folder CKPT+‚Ä¶\"\nlatest = ckpt_dirs[-1]\nprint(\"üîë  D√πng checkpoint:\", latest.name)\n\n# 3) ƒê·ªçc file CKPT.yaml ƒë·ªÉ bi·∫øt c·∫•u tr√∫c\nckpt_yaml = latest / \"CKPT.yaml\"\nassert ckpt_yaml.exists(), f\"‚ùå  Kh√¥ng th·∫•y {ckpt_yaml}\"\nwith open(ckpt_yaml) as f:\n    ckpt_meta = yaml.safe_load(f)\n\n# ckpt_meta[\"modules\"] l√† map recoverable ‚Üí file; th∆∞·ªùng m·ªçi th·ª© ·ªü 'brain.ckpt'\nparam_map = ckpt_meta.get(\"modules\", {})\nprint(\"üìë  modules map:\", param_map)\n\n# 4) N·∫°p brain.ckpt v·ªõi pickle (weights_only=False ‚Äì m·∫∑c ƒë·ªãnh)\nbrain_ckpt = latest / param_map.get(\"brain\", \"optimizer.ckpt\")\nassert brain_ckpt.exists(), f\"‚ùå  Kh√¥ng th·∫•y {brain_ckpt}\"\nstate = torch.load(brain_ckpt, map_location=\"cpu\")   # ‚Üê pickle ƒë·∫ßy ƒë·ªß\nprint(\"üìÇ  Keys trong brain.ckpt:\", list(state.keys())[:8], \"...\")\n\n# 5) L·∫•y state_dict cho embedding_model v√† classifier\n# Tr∆∞·ªùng h·ª£p A: brain.ckpt ch·ª©a dict 2 c·∫•p (embedding_model -> dict)\nif isinstance(state.get(\"embedding_model\"), dict):\n    emb_state = state[\"embedding_model\"]\n    clf_state = state[\"classifier\"]\n# Tr∆∞·ªùng h·ª£p B: ph·∫≥ng ‚Üí l·ªçc prefix\nelse:\n    def slice_state(prefix):\n        return {k[len(prefix)+1:]: v for k, v in state.items()\n                if k.startswith(prefix + \".\")}\n    emb_state = slice_state(\"embedding_model\")\n    clf_state = slice_state(\"classifier\")\n\nembedding_model.load_state_dict(emb_state, strict=False)\nclassifier.load_state_dict(clf_state,   strict=False)\n\n# (t√πy) n·∫øu c√≥ mean_var_norm trong brain.ckpt\nif \"mean_var_norm\" in state:\n    mean_var_norm.load_state_dict(state[\"mean_var_norm\"], strict=False)\n\n# 6) Chuy·ªÉn m·ªçi m√¥-ƒëun sang GPU\nfor mod in [compute_features, mean_var_norm,\n            embedding_model, classifier]:\n    mod.to(\"cuda\")\n\nprint(\"‚úÖ  N·∫°p checkpoint th√†nh c√¥ng ‚Äì m√¥ h√¨nh s·∫µn s√†ng inference\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:43:35.011821Z","iopub.execute_input":"2025-05-30T09:43:35.012083Z","iopub.status.idle":"2025-05-30T09:43:35.633857Z","shell.execute_reply.started":"2025-05-30T09:43:35.012060Z","shell.execute_reply":"2025-05-30T09:43:35.633229Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/speechbrain/utils/checkpoints.py:200: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state_dict = torch.load(path, map_location=device)\n/usr/local/lib/python3.11/dist-packages/speechbrain/processing/features.py:1529: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  stats = torch.load(path, map_location=device)\n/tmp/ipykernel_35/750263957.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  state = torch.load(brain_ckpt, map_location=\"cpu\")   # ‚Üê pickle ƒë·∫ßy ƒë·ªß\n","output_type":"stream"},{"name":"stdout","text":"üîë  D√πng checkpoint: CKPT+2025-05-16+23-44-53+00\nüìë  modules map: {}\nüìÇ  Keys trong brain.ckpt: ['state', 'param_groups'] ...\n‚úÖ  N·∫°p checkpoint th√†nh c√¥ng ‚Äì m√¥ h√¨nh s·∫µn s√†ng inference\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Cell 4 ‚Äì H√†m l·∫•y embedding + cosine score (c√≥ cache)\n\n@functools.lru_cache(maxsize=None)\n@torch.inference_mode()\ndef get_embed(wav_path: str):\n    sig, _ = torchaudio.load(wav_path)\n    if sig.dim() == 2:                      # stereo ‚Üí mono\n        sig = sig.mean(0, keepdim=True)\n\n    feats = mean_var_norm(\n        compute_features(sig.to(\"cuda\")),\n        torch.tensor([sig.shape[-1]], device=\"cuda\")\n    )\n    emb = embedding_model(feats, torch.tensor([feats.shape[1]], device=\"cuda\"))\n    if emb.dim() == 3:                      # [1,T,192] ‚Üí mean T\n        emb = emb.mean(1)\n    return F.normalize(emb.squeeze(0), p=2, dim=-1).half()   # (192,)\n\ndef cosine_score(e1, e2):\n    return float((e1 * e2).sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:43:35.635320Z","iopub.execute_input":"2025-05-30T09:43:35.635519Z","iopub.status.idle":"2025-05-30T09:43:35.641201Z","shell.execute_reply.started":"2025-05-30T09:43:35.635505Z","shell.execute_reply":"2025-05-30T09:43:35.640499Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"# Cell 5 ‚Äì Sinh predictions.txt + submission.zip (private-test)\nimport pandas as pd\n\n# ƒê·ªçc file prompts_sv.csv: m·ªói d√≤ng c√≥ hai t√™n file ngƒÉn c√°ch b·ªüi kho·∫£ng tr·∫Øng\ndf = pd.read_csv(\n    PAIR_FILE,\n    delim_whitespace=True,    # << quan tr·ªçng: parse whitespace\n    header=None,\n    names=[\"wav1\", \"wav2\"]\n)\n\n# T·∫°o file predictions.txt\nwith open(OUT_TXT, \"w\") as fout:\n    for _, row in tqdm.tqdm(df.iterrows(), total=len(df), desc=\"Scoring pairs\"):\n        w1, w2 = row.wav1, row.wav2\n        p1 = (WAV_DIR / w1).as_posix()\n        p2 = (WAV_DIR / w2).as_posix()\n        emb1 = get_embed(p1)\n        emb2 = get_embed(p2)\n        fout.write(f\"{cosine_score(emb1, emb2):.6f}\\n\")\n\nprint(f\"‚ú®  ƒê√£ ghi {len(df)} scores v√†o {OUT_TXT.name}\")\n\n# N√©n zip ƒë·ªÉ n·ªôp\nwith zipfile.ZipFile(ZIP_PATH, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n    zf.write(OUT_TXT, arcname=\"predictions.txt\")\nprint(\"üéâ  File n·ªôp s·∫µn s√†ng ‚Üí\", ZIP_PATH)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:43:35.641995Z","iopub.execute_input":"2025-05-30T09:43:35.642261Z","iopub.status.idle":"2025-05-30T09:47:13.181848Z","shell.execute_reply.started":"2025-05-30T09:43:35.642240Z","shell.execute_reply":"2025-05-30T09:47:13.180972Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/4052694161.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n  df = pd.read_csv(\nScoring pairs: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15971/15971 [03:37<00:00, 73.44it/s] ","output_type":"stream"},{"name":"stdout","text":"‚ú®  ƒê√£ ghi 15971 scores v√†o predictions.txt\nüéâ  File n·ªôp s·∫µn s√†ng ‚Üí /kaggle/working/submission.zip\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Li·ªát k√™ n·ªôi dung /kaggle/working ƒë·ªÉ xem c√≥ submission.zip kh√¥ng\n!ls -lh /kaggle/working\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T10:04:31.602321Z","iopub.execute_input":"2025-05-30T10:04:31.602653Z","iopub.status.idle":"2025-05-30T10:04:31.772004Z","shell.execute_reply.started":"2025-05-30T10:04:31.602631Z","shell.execute_reply":"2025-05-30T10:04:31.771242Z"}},"outputs":[{"name":"stdout","text":"total 200K\n-rw-r--r-- 1 root root 140K May 30 09:47 predictions.txt\ndrwxr-xr-x 2 root root 4.0K May 30 09:24 pretrained_ecapa\n-rw-r--r-- 1 root root  49K May 30 09:47 submission.zip\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"# Cell 6 (tu·ª≥ ch·ªçn) ‚Äì T√≠nh EER offline n·∫øu c√≥ nh√£n\n\nimport pandas as pd, numpy as np\nfrom sklearn.metrics import roc_curve\n\nGT_CSV = VOX_ROOT / \"test_list_gt.csv\"\nif GT_CSV.exists():\n    gt = pd.read_csv(GT_CSV)          # c·ªôt cu·ªëi = label (0/1)\n    scores = np.loadtxt(OUT_TXT)\n    labels = gt.iloc[:, -1].to_numpy()\n\n    fpr, tpr, _ = roc_curve(labels, scores, pos_label=1)\n    eer = fpr[np.nanargmin(np.abs(1 - tpr - fpr))] * 100\n    print(f\"üîé  EER offline = {eer:.2f} %\")\nelse:\n    print(\"‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y test_list_gt.csv ‚Äì b·ªè qua b∆∞·ªõc t√≠nh EER.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-30T09:47:13.182811Z","iopub.execute_input":"2025-05-30T09:47:13.183350Z","iopub.status.idle":"2025-05-30T09:47:13.211161Z","shell.execute_reply.started":"2025-05-30T09:47:13.183324Z","shell.execute_reply":"2025-05-30T09:47:13.209954Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/219218478.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mGT_CSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVOX_ROOT\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"test_list_gt.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mGT_CSV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGT_CSV\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m# c·ªôt cu·ªëi = label (0/1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'VOX_ROOT' is not defined"],"ename":"NameError","evalue":"name 'VOX_ROOT' is not defined","output_type":"error"}],"execution_count":48}]}